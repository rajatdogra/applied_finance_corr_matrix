{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Data Analysis\n",
    "## Correlation Matrix Estimation and Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh, norm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Adjustment Functions\n",
    "\n",
    "First, we'll define the two adjustment methods from Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_decomposition(corr_matrix, epsilon=1e-8):\n",
    "    \"\"\"Adjust correlation matrix using Spectral Decomposition Method.\"\"\"\n",
    "    if isinstance(corr_matrix, pd.DataFrame):\n",
    "        corr_matrix = corr_matrix.values\n",
    "    \n",
    "    eigenvalues, eigenvectors = eigh(corr_matrix)\n",
    "    eigenvalues_adj = np.where(eigenvalues < epsilon, epsilon, eigenvalues)\n",
    "    adj_corr_matrix = eigenvectors @ np.diag(eigenvalues_adj) @ eigenvectors.T\n",
    "    sqrt_diag = np.sqrt(np.diag(adj_corr_matrix))\n",
    "    adj_corr_matrix = adj_corr_matrix / sqrt_diag[:, None] / sqrt_diag[None, :]\n",
    "    \n",
    "    return adj_corr_matrix\n",
    "\n",
    "def alternating_projection(corr_matrix, tolerance=1e-12, tau=1e-8):\n",
    "    \"\"\"Adjust correlation matrix using Alternating Projection Method.\"\"\"\n",
    "    if isinstance(corr_matrix, pd.DataFrame):\n",
    "        corr_matrix = corr_matrix.values\n",
    "    \n",
    "    Y = corr_matrix.copy()\n",
    "    delta_S = 0\n",
    "    k = 1\n",
    "    b = np.ones(corr_matrix.shape[0])\n",
    "    \n",
    "    while True:\n",
    "        R = Y - delta_S\n",
    "        eigenvals_R, eigenvecs_R = eigh(R)\n",
    "        eigenvals_R[eigenvals_R < tau] = tau\n",
    "        X_k = eigenvecs_R @ np.diag(eigenvals_R) @ eigenvecs_R.T\n",
    "        delta_S = X_k - R\n",
    "        Y = X_k - np.diag(X_k.diagonal() - b)\n",
    "        norm_k = norm(X_k.diagonal() - b)\n",
    "        \n",
    "        if norm_k <= tolerance:\n",
    "            break\n",
    "        else:\n",
    "            k += 1\n",
    "            \n",
    "        if k > 10000:\n",
    "            print(f\"Warning: Maximum iterations reached. Current norm: {norm_k}\")\n",
    "            break\n",
    "    \n",
    "    X_k_scalar = np.diag(1/np.sqrt(np.diag(X_k)))\n",
    "    adj_corr_matrix = X_k_scalar @ X_k @ X_k_scalar\n",
    "    distance = np.linalg.norm(corr_matrix - adj_corr_matrix)\n",
    "    \n",
    "    return adj_corr_matrix, k, distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Read the Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the correct path to data files\n",
    "if os.path.exists('../Data_HW-20251128/set_1.xlsx'):\n",
    "    data_path = '../Data_HW-20251128/'\n",
    "elif os.path.exists('Data_HW-20251128/set_1.xlsx'):\n",
    "    data_path = 'Data_HW-20251128/'\n",
    "else:\n",
    "    data_path = '../Data_HW-20251128/'\n",
    "\n",
    "# Read the Excel files\n",
    "set_1_raw = pd.read_excel(data_path + 'set_1.xlsx')\n",
    "set_2_raw = pd.read_excel(data_path + 'set_2.xlsx')\n",
    "set_3_raw = pd.read_excel(data_path + 'set_3.xlsx')\n",
    "\n",
    "print(\"Data files loaded successfully!\")\n",
    "print(f\"\\nSet 1 - Shape: {set_1_raw.shape}\")\n",
    "print(f\"Columns: {list(set_1_raw.columns)}\")\n",
    "print(f\"\\nFirst few rows of Set 1:\")\n",
    "print(set_1_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns (exclude date columns)\n",
    "set_1 = set_1_raw.select_dtypes(include=[np.number])\n",
    "set_2 = set_2_raw.select_dtypes(include=[np.number])\n",
    "set_3 = set_3_raw.select_dtypes(include=[np.number])\n",
    "\n",
    "print(\"Numeric columns selected:\")\n",
    "print(f\"\\nSet 1 - Shape: {set_1.shape}, Columns: {list(set_1.columns)}\")\n",
    "print(f\"Set 2 - Shape: {set_2.shape}, Columns: {list(set_2.columns)}\")\n",
    "print(f\"Set 3 - Shape: {set_3.shape}, Columns: {list(set_3.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Calculate Correlation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrices\n",
    "corr_1 = set_1.corr()\n",
    "corr_2 = set_2.corr()\n",
    "corr_3 = set_3.corr()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CORRELATION MATRIX - SET 1\")\n",
    "print(\"=\"*70)\n",
    "print(corr_1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION MATRIX - SET 2\")\n",
    "print(\"=\"*70)\n",
    "print(corr_2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION MATRIX - SET 3\")\n",
    "print(\"=\"*70)\n",
    "print(corr_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Check if Matrices Need Adjustment\n",
    "\n",
    "A correlation matrix needs adjustment if it is **not positive semi-definite**, which occurs when one or more eigenvalues are negative or zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_positive_definite(corr_matrix, name):\n",
    "    \"\"\"\n",
    "    Check if a correlation matrix is positive definite.\n",
    "    A matrix is positive definite if all eigenvalues are positive.\n",
    "    \"\"\"\n",
    "    eigenvalues, _ = eigh(corr_matrix)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ANALYSIS: {name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Eigenvalues: {eigenvalues}\")\n",
    "    print(f\"Minimum eigenvalue: {eigenvalues.min():.10f}\")\n",
    "    print(f\"Maximum eigenvalue: {eigenvalues.max():.10f}\")\n",
    "    \n",
    "    if eigenvalues.min() > 0:\n",
    "        print(f\"\\n✓ Matrix is POSITIVE DEFINITE\")\n",
    "        print(f\"  All eigenvalues are positive.\")\n",
    "        print(f\"  NO ADJUSTMENT NEEDED.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\n✗ Matrix is NOT POSITIVE DEFINITE\")\n",
    "        print(f\"  Found {(eigenvalues <= 0).sum()} non-positive eigenvalue(s).\")\n",
    "        print(f\"  ADJUSTMENT IS REQUIRED.\")\n",
    "        return False\n",
    "\n",
    "# Check all three matrices\n",
    "is_pd_1 = check_positive_definite(corr_1, \"SET 1\")\n",
    "is_pd_2 = check_positive_definite(corr_2, \"SET 2\")\n",
    "is_pd_3 = check_positive_definite(corr_3, \"SET 3\")\n",
    "\n",
    "needs_adjustment_1 = not is_pd_1\n",
    "needs_adjustment_2 = not is_pd_2\n",
    "needs_adjustment_3 = not is_pd_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification\n",
    "\n",
    "**Why does a correlation matrix need adjustment?**\n",
    "\n",
    "A valid correlation matrix must be **positive semi-definite**, meaning all eigenvalues ≥ 0. When this property is violated:\n",
    "\n",
    "1. **Mathematical invalidity**: The matrix doesn't represent a valid covariance structure\n",
    "2. **Computational issues**: Cannot perform Cholesky decomposition, needed for simulations\n",
    "3. **Statistical problems**: Cannot be used in many multivariate analyses\n",
    "\n",
    "**Common causes:**\n",
    "- **Missing data**: Pairwise correlation calculations with different sample sizes\n",
    "- **Small sample size**: Estimation errors accumulate\n",
    "- **Numerical precision**: Rounding errors in computation\n",
    "- **Data quality**: Inconsistent or contradictory correlation estimates\n",
    "\n",
    "**Decision rule:**\n",
    "- If minimum eigenvalue < 0: **Definitely needs adjustment**\n",
    "- If minimum eigenvalue ≈ 0 (e.g., < 1e-8): **May need adjustment** depending on application\n",
    "- If all eigenvalues > 0: **No adjustment needed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Adjustments to Matrices that Need It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_and_compare(corr_matrix, name):\n",
    "    \"\"\"\n",
    "    Apply both adjustment methods and compare results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ADJUSTING {name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Apply Spectral Decomposition\n",
    "    print(\"\\n[1] Spectral Decomposition Method\")\n",
    "    print(\"-\" * 70)\n",
    "    corr_spectral = spectral_decomposition(corr_matrix)\n",
    "    eigenvals_spectral, _ = eigh(corr_spectral)\n",
    "    distance_spectral = np.linalg.norm(corr_matrix - corr_spectral)\n",
    "    \n",
    "    print(f\"Adjusted eigenvalues: {eigenvals_spectral}\")\n",
    "    print(f\"Minimum eigenvalue:   {eigenvals_spectral.min():.10f}\")\n",
    "    print(f\"Distance from original: {distance_spectral:.10f}\")\n",
    "    \n",
    "    # Apply Alternating Projection\n",
    "    print(\"\\n[2] Alternating Projection Method\")\n",
    "    print(\"-\" * 70)\n",
    "    corr_alt, iterations, distance_alt = alternating_projection(corr_matrix)\n",
    "    eigenvals_alt, _ = eigh(corr_alt)\n",
    "    \n",
    "    print(f\"Number of iterations: {iterations}\")\n",
    "    print(f\"Adjusted eigenvalues: {eigenvals_alt}\")\n",
    "    print(f\"Minimum eigenvalue:   {eigenvals_alt.min():.10f}\")\n",
    "    print(f\"Distance from original: {distance_alt:.10f}\")\n",
    "    \n",
    "    # Comparison\n",
    "    print(\"\\n[3] Comparison\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"Spectral Decomposition distance: {distance_spectral:.10f}\")\n",
    "    print(f\"Alternating Projection distance:  {distance_alt:.10f}\")\n",
    "    print(f\"Difference: {abs(distance_spectral - distance_alt):.10f}\")\n",
    "    print(f\"\\nBetter method (smaller distance): \", end=\"\")\n",
    "    if distance_spectral < distance_alt:\n",
    "        print(\"Spectral Decomposition\")\n",
    "    else:\n",
    "        print(\"Alternating Projection\")\n",
    "    \n",
    "    return corr_spectral, corr_alt\n",
    "\n",
    "# Store adjusted matrices\n",
    "adjusted_matrices = {}\n",
    "\n",
    "if needs_adjustment_1:\n",
    "    corr_1_spectral, corr_1_alt = adjust_and_compare(corr_1, \"SET 1\")\n",
    "    adjusted_matrices['set_1'] = {'spectral': corr_1_spectral, 'alternating': corr_1_alt}\n",
    "\n",
    "if needs_adjustment_2:\n",
    "    corr_2_spectral, corr_2_alt = adjust_and_compare(corr_2, \"SET 2\")\n",
    "    adjusted_matrices['set_2'] = {'spectral': corr_2_spectral, 'alternating': corr_2_alt}\n",
    "\n",
    "if needs_adjustment_3:\n",
    "    corr_3_spectral, corr_3_alt = adjust_and_compare(corr_3, \"SET 3\")\n",
    "    adjusted_matrices['set_3'] = {'spectral': corr_3_spectral, 'alternating': corr_3_alt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Eigenvalue comparison for all three datasets\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "datasets = [('Set 1', corr_1), ('Set 2', corr_2), ('Set 3', corr_3)]\n",
    "needs_adj = [needs_adjustment_1, needs_adjustment_2, needs_adjustment_3]\n",
    "\n",
    "for ax, (name, corr), needs in zip(axes, datasets, needs_adj):\n",
    "    eigenvals, _ = eigh(corr)\n",
    "    colors = ['red' if ev <= 0 else 'green' for ev in eigenvals]\n",
    "    ax.bar(range(len(eigenvals)), eigenvals, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Eigenvalue Index', fontsize=10)\n",
    "    ax.set_ylabel('Eigenvalue', fontsize=10)\n",
    "    ax.set_title(f'{name}\\n{\"✗ Needs Adjustment\" if needs else \"✓ Valid\"}', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Eigenvalue Analysis - All Datasets', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Correlation matrix heatmaps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, (name, corr) in zip(axes, datasets):\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "                vmin=-1, vmax=1, square=True, ax=ax, cbar_kws={'shrink': 0.8})\n",
    "    ax.set_title(name, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Original Correlation Matrices', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Adjustment comparison (only for matrices that need adjustment)\n",
    "if needs_adjustment_1 or needs_adjustment_3:\n",
    "    # Count how many need adjustment\n",
    "    n_to_adjust = sum([needs_adjustment_1, needs_adjustment_3])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_to_adjust, figsize=(7*n_to_adjust, 5))\n",
    "    if n_to_adjust == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    idx = 0\n",
    "    for i, (needs, name) in enumerate([(needs_adjustment_1, 'Set 1'), \n",
    "                                         (needs_adjustment_3, 'Set 3')]):\n",
    "        if needs:\n",
    "            corr = corr_1 if i == 0 else corr_3\n",
    "            \n",
    "            # Get eigenvalues\n",
    "            eigenvals_orig, _ = eigh(corr)\n",
    "            corr_spec = spectral_decomposition(corr)\n",
    "            eigenvals_spec, _ = eigh(corr_spec)\n",
    "            corr_alt, _, _ = alternating_projection(corr)\n",
    "            eigenvals_alt, _ = eigh(corr_alt)\n",
    "            \n",
    "            # Plot\n",
    "            x = np.arange(len(eigenvals_orig))\n",
    "            width = 0.25\n",
    "            \n",
    "            axes[idx].bar(x - width, eigenvals_orig, width, label='Original', \n",
    "                         color='red', alpha=0.7)\n",
    "            axes[idx].bar(x, eigenvals_spec, width, label='Spectral', \n",
    "                         color='blue', alpha=0.7)\n",
    "            axes[idx].bar(x + width, eigenvals_alt, width, label='Alternating', \n",
    "                         color='green', alpha=0.7)\n",
    "            \n",
    "            axes[idx].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "            axes[idx].set_xlabel('Eigenvalue Index', fontsize=11)\n",
    "            axes[idx].set_ylabel('Eigenvalue', fontsize=11)\n",
    "            axes[idx].set_title(f'{name} - Adjustment Comparison', fontsize=12, fontweight='bold')\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "            \n",
    "            idx += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No matrices needed adjustment for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nSet 1: {'✗ Needs adjustment' if needs_adjustment_1 else '✓ No adjustment needed'}\")\n",
    "if needs_adjustment_1:\n",
    "    eigenvals_orig = eigh(corr_1)[0]\n",
    "    print(f\"  Original min eigenvalue: {eigenvals_orig.min():.10f}\")\n",
    "    print(f\"  Reason: Negative eigenvalue (likely due to missing data)\")\n",
    "\n",
    "print(f\"\\nSet 2: {'✗ Needs adjustment' if needs_adjustment_2 else '✓ No adjustment needed'}\")\n",
    "if not needs_adjustment_2:\n",
    "    eigenvals_orig = eigh(corr_2)[0]\n",
    "    print(f\"  Original min eigenvalue: {eigenvals_orig.min():.10f}\")\n",
    "    print(f\"  Reason: All eigenvalues positive (complete data, valid correlations)\")\n",
    "\n",
    "print(f\"\\nSet 3: {'✗ Needs adjustment' if needs_adjustment_3 else '✓ No adjustment needed'}\")\n",
    "if needs_adjustment_3:\n",
    "    eigenvals_orig = eigh(corr_3)[0]\n",
    "    print(f\"  Original min eigenvalue: {eigenvals_orig.min():.10e}\")\n",
    "    print(f\"  Reason: Near-zero eigenvalue (perfect/near-perfect correlations)\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CONCLUSIONS:\")\n",
    "print(\"-\"*70)\n",
    "print(\"\\n1. Both adjustment methods successfully produce positive semi-definite matrices\")\n",
    "print(\"2. Alternating Projection typically provides closer approximation (smaller distance)\")\n",
    "print(\"3. Spectral Decomposition is faster and simpler to implement\")\n",
    "print(\"4. Choice of method depends on application requirements\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
